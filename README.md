# Data Analyst & Machine Learning Portfolio

This repository showcases hands-on projects from the Machine Learning course, covering core machine learning concepts and practical implementations in Python. Each section contains Jupyter notebooks demonstrating algorithms, visualizations, and results.

---


### [Part 1: Data Preprocessing](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%201%20-%20Data%20Preprocessing)
-  **Data Cleaning** – Removing inconsistencies and handling missing values
-  **Encoding Categorical Data** – Converting text labels into numerical format
-  **Splitting Train/Test Sets** – Separating data for training and evaluation
-  **Feature Scaling** – Standardizing feature ranges for optimal model performance

### [Part 2: Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression)
-  **[Simple Linear Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/1.%20Simple%20Linear%20Regression)** – Predicting salaries based on years of experience
-  **[Multiple Linear Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/2.%20Multiple%20Linear%20Regression)** – Predicting startup profit based on marketing, admin, and R&D spending
-  **[Polynomial Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/3.%20Polynomial%20Regression)** – Modeling non-linear relationships between position level and salary
-  **[Support Vector Regression (SVR)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/4.%20Support%20Vector%20Regression)** – Predicting salaries with margin-based support vector technique
-  **[Decision Tree Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/5.%20Decision%20Tree%20Regression)** – Predicting salaries using decision boundaries
-  **[Random Forest Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%202%20-%20Regression/6.%20Random%20Forest%20Regression)** – Predicting salaries with ensemble of decision trees for better accuracy

### [Part 3: Classification](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification)
-  **[Logistic Regression](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/1.%20Logistic%20Regression)** – Predicting whether a customer will purchase a product
-  **[K-Nearest Neighbors (K-NN)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/2.%20K-Nearest%20Neighbor)** – Classifying users based on social network ad data
-  **[Support Vector Machine (SVM)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/3.%20Support%20Vector%20Machine)** – Classifying data using a maximum margin hyperplane
-  **[Kernel SVM](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/4.%20Kernel%20SVM)** – Handling non-linear classification problems
-  **[Naive Bayes](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/5.%20Naive%20Bayes)** – Predicting if users liked a social ad using probabilistic classifiers
-  **[Decision Tree Classification](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/6.%20Decision%20Tree%20Classification)** – Visual decision boundaries to classify purchases
-  **[Random Forest Classification](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%203%20-%20Classification/7.%20Random%20Forest%20Classification)** – Improving classification accuracy with multiple trees

### [Part 4: Clustering](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%204%20-%20Clustering)
-  **[K-Means Clustering](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%204%20-%20Clustering/1.%20K-Means%20Clustering)** – Segmenting mall customers based on income and spending score
-  **[Hierarchical Clustering](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%204%20-%20Clustering/2.%20Hierarchical%20Clustering)** – Building customer segments using a dendrogram approach

### [Part 5: Association Rule Learning](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%205%20-%20Association)
-  **[Apriori](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%205%20-%20Association/1.%20Apriori)** – Mining association rules for market basket analysis
-  **[Eclat](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%205%20-%20Association/2.%20Eclat)** – Discovering itemsets based only on support metrics

### [Part 6: Reinforcement Learning](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%206%20-%20Reinforcement%20Learning)
-  **[Upper Confidence Bound (UCB)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%206%20-%20Reinforcement%20Learning/1.%20Upper%20Confidence%20Bound)** – Choosing the best ad to display using exploration vs exploitation
-  **[Thompson Sampling](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%206%20-%20Reinforcement%20Learning/2.%20Thompson%20Sampling)** – Bayesian approach to ad optimization based on success/failure

### [Part 7: Natural Language Processing](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%207%20-%20Natural%20Language%20Processing)
-  **Sentiment Analysis** – Classifying restaurant reviews as positive or negative using NLP and Bag-of-Words

### [Part 8: Deep Learning](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%208%20-%20Deep%20Learning)
-  **[Artificial Neural Networks (ANN)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%208%20-%20Deep%20Learning/1.%20Artificial%20Neural%20Network)** – Predicting customer churn based on contract and activity data
-  **[Convolutional Neural Networks (CNN)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%208%20-%20Deep%20Learning/2.%20Convolutional%20Neural%20Network)** – Image classification of cats vs dogs

### [Part 9: Dimensionality Reduction](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%209%20-%20Dimensional%20Reduction)
-  **[Principal Component Analysis (PCA)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%209%20-%20Dimensional%20Reduction/1.%20Principal%20Component%20Analysis)** – Reducing features in wine dataset for classification
-  **[Linear Discriminant Analysis (LDA)](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%209%20-%20Dimensional%20Reduction/2.%20Linear%20Discriminant%20Analysis)** – Maximizing class separation before classification
-  **[Kernel PCA](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%209%20-%20Dimensional%20Reduction/3.%20Kernel%20PCA)** – Applying non-linear dimensionality reduction techniques

### [Part 10: Model Selection & Boosting](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%2010.%20Model%20Selection%20%26%20Boosting)
-  **[Model Selection](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%2010.%20Model%20Selection%20%26%20Boosting/1.%20Model%20Selection)** – Comparing models using k-Fold Cross Validation
-  **[XGBoost](https://github.com/RyanTanjaya/ML-Projects/tree/main/Machine%20Learning%20Portofolio/Part%2010.%20Model%20Selection%20%26%20Boosting/2.%20XG%20Boost)** – Improving model accuracy with gradient boosting

---

---

## Tools & Technologies
- Python
- NumPy, pandas
- Matplotlib, seaborn
- scikit-learn
- TensorFlow, Keras
- Google Colab / Jupyter Notebook

---

## How to Use
1. Clone the repo or download the notebooks
2. Open `.ipynb` files with [Google Colab](https://colab.research.google.com) or Jupyter Notebook
3. Run the cells and explore the visual outputs

---

## Contact
Feel free to connect on [LinkedIn](https://www.linkedin.com/in/ryan-tanjaya-2987521b3/) or message me if you have any questions about the projects!

